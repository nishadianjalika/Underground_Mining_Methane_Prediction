{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d215265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "from scipy.fft import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f804ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(sensor_data):\n",
    "    features = []\n",
    "\n",
    "    # Basic statistical features\n",
    "    mean = np.mean(sensor_data)\n",
    "    std = np.std(sensor_data)\n",
    "    min_val = np.min(sensor_data)\n",
    "    max_val = np.max(sensor_data)\n",
    "\n",
    "    # Top 5 minimal and maximal values\n",
    "    top5_min = np.mean(sorted(sensor_data)[:5])\n",
    "    top5_max = np.mean(sorted(sensor_data)[-5:])\n",
    "\n",
    "    # Standard deviations from the mean\n",
    "    min_std = (min_val - mean) / std if std != 0 else 0\n",
    "    max_std = (max_val - mean) / std if std != 0 else 0\n",
    "\n",
    "    # FFT-based features\n",
    "    fft_vals = fft(sensor_data)\n",
    "    top_freqs = np.abs(fft_vals)[3:6]  # Ignoring the first three frequencies\n",
    "\n",
    "    # Linear regression parameters\n",
    "    # slope, intercept, _, _, std_err = linregress(range(len(sensor_data)), sensor_data)\n",
    "\n",
    "    # Extend the feature list\n",
    "    features.extend([\n",
    "        mean, std, min_val, max_val, top5_min, top5_max,\n",
    "        min_std, max_std, np.max(top_freqs)\n",
    "        # , slope, intercept, std_err\n",
    "    ])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10da1d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_column_names(sensors):\n",
    "    feature_types = [\n",
    "        'mean', 'std', 'min', 'max',\n",
    "        'top5_min', 'top5_max',\n",
    "        'min_std', 'max_std',\n",
    "        'top_freqs_max'\n",
    "        # , 'slope', 'intercept', 'std_err'\n",
    "    ]\n",
    "    column_names = []\n",
    "    \n",
    "    for sensor in sensors:\n",
    "        for feature in feature_types:\n",
    "            # Format: Sensor_Feature (e.g., AN311_mean)\n",
    "            column_name = f'{sensor}_{feature}'\n",
    "            column_names.append(column_name)\n",
    "    \n",
    "    return column_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41b0afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_for_all_sensors(df):\n",
    "    feature_data = []\n",
    "    sensors = [\n",
    "        'AN311', 'AN422', 'AN423', 'TP1721', 'RH1722', 'BA1723', \n",
    "        'TP1711', 'RH1712', 'BA1713', 'MM252', 'MM261', 'MM262', \n",
    "        'MM263', 'MM264', 'MM256', 'MM211', 'CM861', 'CR863', \n",
    "        'P_864', 'TC862', 'WM868', 'AMP1_IR', 'AMP2_IR', 'DMP3_IR', \n",
    "        'DMP4_IR', 'AMP5_IR', 'F_SIDE', 'V'\n",
    "    ]\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        row_features = []\n",
    "        for sensor in sensors:\n",
    "            sensor_columns = [f'{sensor}_value_{i}' for i in range(1, 601)]  # Assuming 600 readings per sensor\n",
    "            sensor_data = row[sensor_columns].values\n",
    "\n",
    "            # Extract features for this sensor\n",
    "            sensor_features = extract_features(sensor_data)\n",
    "            \n",
    "            # Add the sensor features to the row features\n",
    "            row_features.extend(sensor_features)\n",
    "\n",
    "        # Append the row's features to the overall feature data\n",
    "        feature_data.append(row_features)\n",
    "    \n",
    "    # Generate column names\n",
    "    column_names = generate_column_names(sensors)\n",
    "    \n",
    "    # Convert the feature data into a DataFrame with proper column names\n",
    "    feature_df = pd.DataFrame(feature_data, columns=column_names)\n",
    "    return feature_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80035522-7302-449e-9899-52c230d05349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store all feature-engineered data\n",
    "all_features_df = pd.DataFrame()\n",
    "\n",
    "# Load the zip file in chunks and process each chunk\n",
    "chunksize = 1000  # Adjust this size based on available memory\n",
    "testdata = '../extracted_data/testDataFull.csv'\n",
    "\n",
    "for chunk in pd.read_csv(testdata, chunksize=chunksize):\n",
    "    # Apply the feature engineering process to the current chunk\n",
    "    feature_df = feature_engineering_for_all_sensors(chunk)\n",
    "    \n",
    "    # Append the processed chunk to the final DataFrame\n",
    "    all_features_df = pd.concat([all_features_df, feature_df], ignore_index=True)\n",
    "    # print(all_features_df.head())\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b56fbaa0-727f-4859-b42a-1841a292a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final feature-engineered data into a compressed zip file\n",
    "output_zip_path = '../extracted_data/feature_extracted_data/testData_features_01_01.csv'\n",
    "all_features_df.to_csv(output_zip_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "addf0ea7-155c-4cd9-b538-19aec9031cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5076, 252)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58f053-9567-45c7-aa66-2018dbfa5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45feca54-42d1-4190-8ee7-863ed57c219d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
